"""
Dropout Rate Comparison: Finding the Optimal Rate
==================================================

PREREQUISITES:
- Complete network_3.2.0.py (understand dropout basics)
- Understand: how dropout works, why it prevents overfitting

THIS EXPERIMENT:
Systematically compares different dropout rates to find the optimal value.
Tests p = [0.2, 0.5, 0.8] to understand the trade-off between regularization
strength and model capacity.

THE DROPOUT RATE SPECTRUM:

p = 0.0 (No Dropout):
  ‚Ä¢ All neurons always active
  ‚Ä¢ Maximum model capacity
  ‚Ä¢ Problem: Severe overfitting with large networks
  ‚Ä¢ Use case: Tiny networks, no overfitting risk

p = 0.2 (Light Dropout):
  ‚Ä¢ Drops 20% of neurons ‚Üí keeps 80%
  ‚Ä¢ Mild regularization
  ‚Ä¢ Most capacity retained
  ‚Ä¢ Use case: Moderate overfitting, smaller networks

p = 0.5 (Standard Dropout):
  ‚Ä¢ Drops 50% of neurons ‚Üí keeps 50%
  ‚Ä¢ Strong regularization
  ‚Ä¢ Balance between capacity and regularization
  ‚Ä¢ Use case: MOST COMMON (industry default!)

p = 0.8 (Heavy Dropout):
  ‚Ä¢ Drops 80% of neurons ‚Üí keeps only 20%!
  ‚Ä¢ Very strong regularization
  ‚Ä¢ Risk of underfitting (too much regularization)
  ‚Ä¢ Use case: Extreme overfitting (rarely needed)

THE TRADE-OFF:

Too Little Dropout (p < 0.3):
  ‚Ä¢ Network has too much capacity
  ‚Ä¢ Can memorize training data
  ‚Ä¢ Overfitting: train accuracy >> validation accuracy
  ‚Ä¢ Example: train 100%, validation 98% (2% gap!)

Optimal Dropout (p ‚âà 0.5):
  ‚Ä¢ Perfect balance of capacity and regularization
  ‚Ä¢ Network forced to learn robust features
  ‚Ä¢ No overfitting: train ‚âà validation accuracy
  ‚Ä¢ Example: train 99%, validation 99% (0% gap!)

Too Much Dropout (p > 0.7):
  ‚Ä¢ Network has too little capacity
  ‚Ä¢ Can't learn complex patterns
  ‚Ä¢ Underfitting: both train and validation low
  ‚Ä¢ Example: train 96%, validation 96% (network too weak!)

THE EXPERIMENT:

We train three identical CNN architectures with different dropout rates:

Network A (p=0.2 - Light Dropout):
  Conv ‚Üí Conv ‚Üí FC (dropout 0.2) ‚Üí Softmax
  Expected: ~98.7% (slight overfitting)

Network B (p=0.5 - Standard Dropout):
  Conv ‚Üí Conv ‚Üí FC (dropout 0.5) ‚Üí Softmax
  Expected: ~99.0% (optimal balance!)

Network C (p=0.8 - Heavy Dropout):
  Conv ‚Üí Conv ‚Üí FC (dropout 0.8) ‚Üí Softmax
  Expected: ~98.2% (underfitting, too much regularization)

Result: p=0.5 is optimal for most networks!

Expected Results:
- Light dropout (p=0.2): ~98.7% (minor overfitting)
- Standard dropout (p=0.5): ~99.0% (optimal!)
- Heavy dropout (p=0.8): ~98.2% (underfitting)
- Key lesson: p=0.5 is the sweet spot for most cases

WHY p=0.5 IS OPTIMAL:

Mathematical Intuition:
  ‚Ä¢ With p=0.5, each neuron is present 50% of the time
  ‚Ä¢ Maximum entropy: most uncertainty, strongest regularization
  ‚Ä¢ While still maintaining reasonable capacity
  ‚Ä¢ Sweet spot between regularization and expressiveness

Empirical Evidence:
  ‚Ä¢ Tested across many datasets and architectures
  ‚Ä¢ Consistently performs best or near-best
  ‚Ä¢ Industry standard in AlexNet, VGG, etc.
  ‚Ä¢ Safe default choice

Information Theory:
  ‚Ä¢ p=0.5 maximizes information about which neurons are essential
  ‚Ä¢ Forces network to learn most robust representations
  ‚Ä¢ Optimal redundancy without excessive capacity loss

PRACTICAL GUIDELINES:

When to Use Different Dropout Rates:

p = 0.1-0.2 (Light):
  ‚úì Small networks (<1M parameters)
  ‚úì Small datasets (<10K examples)
  ‚úì Convolutional layers
  ‚úì When seeing slight underfitting

p = 0.5 (Standard):
  ‚úì DEFAULT CHOICE for FC layers
  ‚úì Medium to large networks
  ‚úì Standard datasets (MNIST, CIFAR, etc.)
  ‚úì When in doubt, use this!

p = 0.7-0.8 (Heavy):
  ‚úì Extreme overfitting cases
  ‚úì Very large networks (>10M parameters)
  ‚úì Very small datasets (<1K examples)
  ‚úì Rarely needed in practice

NEXT STEPS:
- network_3.2.2.py: Dropout vs L2 direct comparison
- network_3.2.3.py: Combined dropout + L2 for maximum performance

Run: python network_3.2.1.py
"""

import sys
sys.path.append('../src')
import network3
from network3 import Network, ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer, ReLU

def main():
    # ========================================================================
    # EXPERIMENT: Dropout Rate Comparison
    # ========================================================================
    print("=" * 75)
    print("DROPOUT RATE COMPARISON: Finding the Sweet Spot")
    print("=" * 75)

    # Load MNIST data once (shared for all experiments)
    training_data, validation_data, test_data = network3.load_data_shared()
    mini_batch_size = 10

    # ========================================================================
    # EXPERIMENT A: Light Dropout (p=0.2)
    # ========================================================================
    # HYPOTHESIS:
    #   ‚Ä¢ Drops only 20% of neurons ‚Üí retains 80% capacity
    #   ‚Ä¢ Mild regularization
    #   ‚Ä¢ May still show minor overfitting
    #   ‚Ä¢ Expected: ~98.7% (good but not optimal)
    #
    # EXPECTED BEHAVIOR:
    #   ‚Ä¢ Training accuracy: ~99.5% (high capacity, can fit well)
    #   ‚Ä¢ Validation accuracy: ~98.7%
    #   ‚Ä¢ Gap: ~0.8% (minor overfitting detected)
    #   ‚Ä¢ Conclusion: Not enough regularization
    
    print("\n" + "=" * 75)
    print("[EXPERIMENT A: Light Dropout p=0.2]")
    print("=" * 75)
    
    # Build network with light dropout (keeps 80% of neurons)
    layer1_light = ConvPoolLayer(
        filter_shape=(20, 1, 5, 5),
        image_shape=(mini_batch_size, 1, 28, 28),
        poolsize=(2, 2),
        activation_fn=ReLU
    )
    
    layer2_light = ConvPoolLayer(
        filter_shape=(40, 20, 5, 5),
        image_shape=(mini_batch_size, 20, 12, 12),
        poolsize=(2, 2),
        activation_fn=ReLU
    )
    
    layer3_light = FullyConnectedLayer(
        n_in=40*4*4,
        n_out=100,
        activation_fn=ReLU,
        p_dropout=0.2                            # Light dropout: keeps 80%
    )
    
    layer4_light = SoftmaxLayer(
        n_in=100,
        n_out=10,
        p_dropout=0.0
    )
    
    net_light = Network([layer1_light, layer2_light, layer3_light, layer4_light], 
                        mini_batch_size)
    
    print("Training with LIGHT DROPOUT (p=0.2)...")
    
    # Train with light dropout
    net_light.SGD(training_data, 30, mini_batch_size, 0.03,
                  validation_data, test_data, lmbda=0.1)

    # ========================================================================
    # EXPERIMENT B: Standard Dropout (p=0.5)
    # ========================================================================
    # HYPOTHESIS:
    #   ‚Ä¢ Drops 50% of neurons ‚Üí retains 50% capacity
    #   ‚Ä¢ Strong regularization
    #   ‚Ä¢ Optimal balance of capacity and regularization
    #   ‚Ä¢ Expected: ~99.0% (BEST PERFORMANCE!)
    #
    # EXPECTED BEHAVIOR:
    #   ‚Ä¢ Training accuracy: ~99%
    #   ‚Ä¢ Validation accuracy: ~99%
    #   ‚Ä¢ Gap: ~0% (no overfitting!)
    #   ‚Ä¢ Conclusion: Perfect balance
    
    print("\n" + "=" * 75)
    print("[EXPERIMENT B: Standard Dropout p=0.5]")
    print("=" * 75)
    
    # Build network with standard dropout
    layer1_standard = ConvPoolLayer(
        filter_shape=(20, 1, 5, 5),
        image_shape=(mini_batch_size, 1, 28, 28),
        poolsize=(2, 2),
        activation_fn=ReLU
    )
    
    layer2_standard = ConvPoolLayer(
        filter_shape=(40, 20, 5, 5),
        image_shape=(mini_batch_size, 20, 12, 12),
        poolsize=(2, 2),
        activation_fn=ReLU
    )
    
    layer3_standard = FullyConnectedLayer(
        n_in=40*4*4,
        n_out=100,
        activation_fn=ReLU,
        p_dropout=0.5                            # Standard dropout: keeps 50%
    )
    
    layer4_standard = SoftmaxLayer(
        n_in=100,
        n_out=10,
        p_dropout=0.0
    )
    
    net_standard = Network([layer1_standard, layer2_standard, layer3_standard, layer4_standard],
                          mini_batch_size)
    
    print("Training with STANDARD DROPOUT (p=0.5)...")
    
    # Train with standard dropout
    net_standard.SGD(training_data, 30, mini_batch_size, 0.03,
                    validation_data, test_data, lmbda=0.1)

    # ========================================================================
    # EXPERIMENT C: Heavy Dropout (p=0.8)
    # ========================================================================
    # HYPOTHESIS:
    #   ‚Ä¢ Drops 80% of neurons ‚Üí retains only 20% capacity!
    #   ‚Ä¢ Very strong regularization (possibly too strong)
    #   ‚Ä¢ May underfit (not enough capacity to learn)
    #   ‚Ä¢ Expected: ~98.2% (worse than optimal)
    #
    # EXPECTED BEHAVIOR:
    #   ‚Ä¢ Training accuracy: ~98.5% (can't fit training data well)
    #   ‚Ä¢ Validation accuracy: ~98.2%
    #   ‚Ä¢ Gap: ~0.3% (but BOTH are lower than optimal!)
    #   ‚Ä¢ Conclusion: Too much regularization, underfitting
    
    print("\n" + "=" * 75)
    print("[EXPERIMENT C: Heavy Dropout p=0.8]")
    print("=" * 75)
    
    # Build network with heavy dropout
    layer1_heavy = ConvPoolLayer(
        filter_shape=(20, 1, 5, 5),
        image_shape=(mini_batch_size, 1, 28, 28),
        poolsize=(2, 2),
        activation_fn=ReLU
    )
    
    layer2_heavy = ConvPoolLayer(
        filter_shape=(40, 20, 5, 5),
        image_shape=(mini_batch_size, 20, 12, 12),
        poolsize=(2, 2),
        activation_fn=ReLU
    )
    
    layer3_heavy = FullyConnectedLayer(
        n_in=40*4*4,
        n_out=100,
        activation_fn=ReLU,
        p_dropout=0.8                            # Heavy dropout: keeps only 20%!
    )
    
    layer4_heavy = SoftmaxLayer(
        n_in=100,
        n_out=10,
        p_dropout=0.0
    )
    
    net_heavy = Network([layer1_heavy, layer2_heavy, layer3_heavy, layer4_heavy],
                       mini_batch_size)
    
    print("Training with HEAVY DROPOUT (p=0.8)...")
    
    # Train with heavy dropout
    net_heavy.SGD(training_data, 30, mini_batch_size, 0.03,
                 validation_data, test_data, lmbda=0.1)

    # ========================================================================
    # Results Summary and Analysis
    # ========================================================================
    # EXPECTED RESULTS:
    # ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    # ‚îÇ Dropout Rate ‚îÇ Keep Rate   ‚îÇ Val Accuracy ‚îÇ Gap     ‚îÇ Assessment  ‚îÇ
    # ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    # ‚îÇ p=0.2 (light)‚îÇ 80% neurons ‚îÇ   ~98.7%     ‚îÇ ~0.8%   ‚îÇ Minor O/F   ‚îÇ
    # ‚îÇ p=0.5 (std)  ‚îÇ 50% neurons ‚îÇ   ~99.0%     ‚îÇ ~0.0%   ‚îÇ OPTIMAL ‚úì   ‚îÇ
    # ‚îÇ p=0.8 (heavy)‚îÇ 20% neurons ‚îÇ   ~98.2%     ‚îÇ ~0.3%   ‚îÇ Underfitting‚îÇ
    # ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    #
    # KEY FINDINGS:
    #
    # 1. LIGHT DROPOUT (p=0.2) - Not Enough Regularization
    #    ‚Ä¢ Retains 80% capacity ‚Üí almost like no dropout
    #    ‚Ä¢ Network can still memorize training patterns
    #    ‚Ä¢ Training: 99.5%, Validation: 98.7% ‚Üí Gap indicates minor overfitting
    #    ‚Ä¢ Verdict: Good but not optimal
    #
    # 2. STANDARD DROPOUT (p=0.5) - Sweet Spot! üéØ
    #    ‚Ä¢ Retains 50% capacity ‚Üí perfect balance
    #    ‚Ä¢ Strong enough regularization to prevent overfitting
    #    ‚Ä¢ Training: 99%, Validation: 99% ‚Üí No gap, excellent generalization
    #    ‚Ä¢ Verdict: OPTIMAL CHOICE (industry standard!)
    #
    # 3. HEAVY DROPOUT (p=0.8) - Too Much Regularization
    #    ‚Ä¢ Retains only 20% capacity ‚Üí severe capacity loss
    #    ‚Ä¢ Network can't learn complex patterns
    #    ‚Ä¢ Training: 98.5%, Validation: 98.2% ‚Üí Both low (underfitting)
    #    ‚Ä¢ Verdict: Excessive, hurts performance
    #
    # WHY p=0.5 IS THE INDUSTRY STANDARD:
    #
    # Mathematical Reason:
    #   ‚Ä¢ Maximizes entropy in neuron presence/absence
    #   ‚Ä¢ Each neuron has equal chance of being present/absent
    #   ‚Ä¢ Optimal uncertainty ‚Üí strongest regularization without capacity loss
    #
    # Empirical Reason:
    #   ‚Ä¢ Tested on thousands of architectures and datasets
    #   ‚Ä¢ Consistently best or near-best performance
    #   ‚Ä¢ Safe default when unsure
    #
    # Practical Reason:
    #   ‚Ä¢ Works for most network sizes (small to large)
    #   ‚Ä¢ Works for most datasets (small to large)
    #   ‚Ä¢ Robust to hyperparameter misspecification
    #
    # WHEN TO DEVIATE FROM p=0.5:
    #
    # Use LIGHTER dropout (p=0.2-0.3) when:
    #   ‚úì Small network (few parameters)
    #   ‚úì Small dataset (risk of underfitting)
    #   ‚úì Convolutional layers (built-in regularization)
    #
    # Use HEAVIER dropout (p=0.6-0.7) when:
    #   ‚úì Very large network (many parameters)
    #   ‚úì Large dataset (lots of training data)
    #   ‚úì Severe overfitting even with p=0.5
    #   ‚úì Rarely needed in practice!
    #
    # Never use p > 0.8:
    #   ‚úó Too extreme, almost always hurts performance
    #   ‚úó Better to reduce network size instead
    #
    # THE GOLDILOCKS PRINCIPLE:
    #   ‚Ä¢ p=0.2: Too little regularization (overfitting)
    #   ‚Ä¢ p=0.8: Too much regularization (underfitting)
    #   ‚Ä¢ p=0.5: Just right! (optimal balance)
    #
    # COMPARISON TO OTHER TECHNIQUES:
    #
    # No Regularization:    Training 100%, Validation 97% (3% gap)
    # L2 Regularization:    Training 99.5%, Validation 98.5% (1% gap)
    # Dropout p=0.5:        Training 99%, Validation 99% (0% gap) ‚Üê Winner!
    # Dropout p=0.5 + L2:   Training 99%, Validation 99.2% ‚Üê Best overall!
    #
    # REAL-WORLD IMPACT:
    #
    # AlexNet (2012): Used p=0.5 in FC layers, key to winning ImageNet
    # VGGNet (2014): p=0.5 in all FC layers, adopted industry-wide
    # Modern CNNs: ResNets use less (batch norm helps), but p=0.5 remains safe default
    #
    # PRACTICAL TAKEAWAY:
    #   "When in doubt, use p=0.5 for FC layers!"
    #   This simple rule works 90% of the time.
    
    print("\n" + "=" * 75)
    print("RESULTS SUMMARY")
    print("=" * 75)
    print("Next: network_3.2.2.py for direct Dropout vs L2 comparison")

if __name__ == "__main__":
    main()

